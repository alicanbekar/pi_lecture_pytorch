{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "* arrange order of material\n",
    "* new task before any training: load some simulation data and visualize a simulation\n",
    "    * image plot\n",
    "    * v/z at a few times\n",
    "* include multiple ICs for supervised training. update existing code that uses the dataloader etc.!\n",
    "* provide mask as an input channel always (even for unet)\n",
    "* new first task: train without using fixed BCs using UnetBC\n",
    "  * visualize results after training\n",
    "  * image plots v/z ref/est/diff\n",
    "  * plot v/z at some chosen time points (ref/est)\n",
    "  * scatter plot of delta v and delta z ref vs. est (over all locations / time points)\n",
    "* rename updates to delta_zeta, delta_v\n",
    "* visualization code\n",
    "  * visualize numerical simulations: give them an example for plotting a simulation, ask them to do a minor variation on this\n",
    "  * give instructions\n",
    "* flux task\n",
    "  * before implementing flux net, have students graph total mass over time of data-driven BCnet\n",
    "  * change flux output so z fluxes defined on vel points, velocities still as tendencies. keep BC constraint\n",
    "  * standard output visualization for fluxnet\n",
    "  * compare overall error and total mass over time of fluxnet to BCnet\n",
    "* new task: hybrid net with supervised loss\n",
    "  * inputs -> net -> flux -> zeta -> u. keep imposing BCs.\n",
    "  * train on same supervised loss as before\n",
    "  * plots, comparisons, etc.\n",
    "* final task: unsupervised learning\n",
    "  * pde loss from $A\\zeta - b$\n",
    "  * use library of system states, randomly sample from these to generate each batch. restart with new random state when integrating past $t_\\text{max}$.\n",
    "* link to papers: unet, \n",
    "* further reading\n",
    "* student version\n",
    "\n",
    "optional:\n",
    "* remove order parameter (multiple inputs time steps)?\n",
    "* extra tasks: change hyperparams, multiple random seeds\n",
    "* separate cell and markdown explanation of random seeding func\n",
    "* include time/space axis information in the hdf5 file, and save it in the dataset objects and use it for plotting\n",
    "* refactor dataset so it's just a tensordataset. do sequence building etc. in the dataloader instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SW Equations and Custom Dataset for SW Simulation Data\n",
    "\n",
    "We are interested in solving the following form of Shallow Water Equations\n",
    "\n",
    "$\\dfrac{\\partial v}{\\partial t} + \\dfrac{c_D}{h}v|v|+g\\dfrac{\\partial \\zeta}{\\partial x} = 0$\n",
    "\n",
    "$\\dfrac{\\partial \\zeta}{\\partial t} + \\dfrac{\\partial (vh)}{\\partial x}=0$\n",
    "\n",
    "where $v(x, t)$ is the velocity, $Î¶(x, t)$ is the positive or negative surface disturbance and $h(x, t) = \\zeta(x, t) + h_0$ is the total depth. $c_D$ and $g$ correspond to drag coefficient and graviational acceleration respectively. The first equation describes Newton's second law ($F=ma$) acting on a fluid parcel, while the second models mass conservation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem we want to solve\n",
    "### Time integration of PDEs\n",
    "Given any **system state** at time $t$ for all locations $x$:\n",
    "$$\\forall x: \\left(v(x, t), \\zeta(x,t) \\right)$$\n",
    "we want to time-integrate the SWEs to obtain the system state at time $t+\\Delta$\n",
    "$$\\forall x:\\left(v(x, t+\\Delta t), \\zeta(x, t+\\Delta t) \\right) = \\left(\n",
    "\\int_t^{t+\\Delta t} \\frac{\\partial v(x, t)}{\\partial t}, \n",
    "\\int_t^{t+\\Delta t} \\frac{\\partial \\zeta(\\cdot,t)}{\\partial t}\n",
    "\\right) $$\n",
    "we will consider the case where we deal with initial conditions and time-integrated outputs only on an evenly spaced grid with spacing $\\Delta x$, and a fixed time step $\\Delta t$.\n",
    "\n",
    "\n",
    "### Classical PDE integration\n",
    "Classical physics-based numerical methods compute these updates by calculating partial derivatives in space and time. Explicit methods do these calculations at time steps where $v,\\zeta$ are already known, simplifying calculationg but often requiring very small time steps to achieve accuracy and stability, often at high computational cost. (Semi)implicit methods can take larger time steps but most iteratively solve a system of equations at each time step until convergence, which can also be costly.\n",
    "\n",
    "We'll discuss the discretization and time stepping used to solve this PDE in one of our later tasks. For now, it's enough to know that we've generated some simulation data from numerical simulation code, and we'll use that data to train neural networks and as a \"ground truth\" reference.\n",
    "\n",
    "### Problem statement\n",
    "In this tutorial, our goal is to **train a neural network to carry out time integration of SWEs** by $\\Delta t$, such that the results match a semiimplicit scheme. By replacing the iterative solving operation of the numerical scheme with a forward pass through a neural network, we aim to produce a fast time-integration method whos computation time does not depend on the input data.\n",
    "\n",
    "While we will not focus on computation times here due to using simplified, lightweight 1-D versions of the numerical model and deep learning architecture, this technique has demonstrated impressive speed increases compared to classical numerical solvers when applied to 2D and 3D fluid dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with the Dataset\n",
    "\n",
    "In this section, we'll import and use custom PyTorch class to load SWE simulation data from an HDF5 file. If you'd like to see how this class works later you can read through the code [here](https://github.com/alicanbekar/pi_lecture_pytorch/blob/main/sw_dataset.ipynb), but for now that isn't necessary. This dataset class is responsible for:\n",
    "1. Reading data from an HDF5 file.\n",
    "2. Normalizing the data, so that $\\zeta$ and $v$ both range from roughly -1 to 1.\n",
    "3. Splitting the data into training, validation, and testing datasets.\n",
    "4. Retrieving sequences of SWE system state to create inputs and outputs for the trained models.\n",
    "\n",
    "Run the next cell to install the necessary code and download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q import-ipynb\n",
    "import import_ipynb\n",
    "!wget https://raw.githubusercontent.com/alicanbekar/pi_lecture_pytorch/main/sw_dataset.ipynb\n",
    "!wget !wget https://raw.githubusercontent.com/alicanbekar/pi_lecture_pytorch/main/simulation_data.h5\n",
    "%run sw_dataset.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data\n",
    "Run the following cells to retrieve and plot some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SWDataset(file_path=\"simulation_data.h5\", normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pytorch tensors to store zeta/vel\n",
    "zeta = torch.cat([data[i][0][0] for i in range(len(data))], axis=0)\n",
    "vel = torch.cat([data[i][0][1] for i in range(len(data))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(vel.detach().numpy())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the U-Net Model for SW Simulations\n",
    "\n",
    "U-Net is a convolutional neural network architecture primarily used for biomedical image segmentation. In our case, we will adapt U-Net to handle 1D data from the SW simulations.\n",
    "\n",
    "The U-Net architecture is symmetric, and it consists of an encoding (downsampling) path, followed by a decoding (upsampling) path. Skip connections are used to pass the information from the encoding path to the decoding path, which helps the network retain spatial details.\n",
    "\n",
    "Let's walk through the code and its structure:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, order):\n",
    "        super(UNet, self).__init__()\n",
    "        self.order = order\n",
    "\n",
    "        # Initial convolution layers for two different input types\n",
    "        self.conv_zeta = nn.Conv1d(self.order, 8, kernel_size=3, padding=1)\n",
    "        self.conv_vel = nn.Conv1d(self.order, 8, kernel_size=4, padding=1)\n",
    "\n",
    "        # Encoder (downsampling) blocks\n",
    "        self.enc1 = self.u_net_block(16, 16)\n",
    "        self.enc2 = self.u_net_block(16, 32)\n",
    "        self.enc3 = self.u_net_block(32, 64)\n",
    "        self.enc4 = self.u_net_block(64, 128)\n",
    "        self.enc5 = self.u_net_block(128, 256)\n",
    "\n",
    "        # Pooling layer for downsampling\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "\n",
    "        # Upsampling layers\n",
    "        self.up1 = nn.ConvTranspose1d(256, 128, kernel_size=2, stride=2)\n",
    "        self.up2 = nn.ConvTranspose1d(128, 64, kernel_size=2, stride=2)\n",
    "        self.up3 = nn.ConvTranspose1d(64, 32, kernel_size=2, stride=2)\n",
    "        self.up4 = nn.ConvTranspose1d(32, 16, kernel_size=2, stride=2)\n",
    "\n",
    "        # Decoder (upsampling) blocks\n",
    "        self.dec1 = self.u_net_block(256, 128)\n",
    "        self.dec2 = self.u_net_block(128, 64)\n",
    "        self.dec3 = self.u_net_block(64, 32)\n",
    "        self.dec4 = self.u_net_block(32, 16)\n",
    "\n",
    "        # Output convolution layers\n",
    "        self.output_dec_zeta = nn.Conv1d(16, 1, kernel_size=3, padding=1)\n",
    "        self.output_dec_vel = nn.Conv1d(16, 1, kernel_size=2, padding=1)\n",
    "\n",
    "    def u_net_block(self, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        Creates a U-Net block with two convolution layers followed by batch normalization and ReLU activation.\n",
    "        \"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x_zeta, x_vel):\n",
    "        # Initial convolution operations\n",
    "        x_zeta = self.conv_zeta(x_zeta)\n",
    "        x_vel = self.conv_vel(x_vel)\n",
    "\n",
    "        # Concatenate the two feature maps along the channel dimension\n",
    "        x_combined = torch.cat([x_vel, x_zeta], dim=1)\n",
    "\n",
    "        # Encoding process\n",
    "        e1 = self.enc1(x_combined)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        e4 = self.enc4(self.pool(e3))\n",
    "        e5 = self.enc5(self.pool(e4))\n",
    "\n",
    "        # Decoding process with skip connections\n",
    "        d1 = self.up1(e5)\n",
    "        d1 = torch.cat([d1, e4], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "\n",
    "        d2 = self.up2(d1)\n",
    "        d2 = torch.cat([d2, e3], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "\n",
    "        d3 = self.up3(d2)\n",
    "        d3 = torch.cat([d3, e2], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "\n",
    "        d4 = self.up4(d3)\n",
    "        d4 = torch.cat([d4, e1], dim=1)\n",
    "        d4 = self.dec4(d4)\n",
    "\n",
    "        # Separate output convolutions\n",
    "        dt_zeta = self.output_dec_zeta(d4)\n",
    "        dt_vel = self.output_dec_vel(d4)\n",
    "        return dt_zeta, dt_vel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guidelines:\n",
    "\n",
    "- **u_net_block**: This function should return a sequential block that performs two sets of (convolution -> batch normalization -> ReLU activation). You can chain these operations using `nn.Sequential`.\n",
    "\n",
    "- **Encoder**: Remember, as you go deeper into the encoder, you are reducing the spatial dimensions (using max pooling) and typically increasing the number of channels.\n",
    "\n",
    "- **Decoder**: It's the reverse of the encoder. For each block, you will upsample to increase spatial dimensions and typically decrease the number of channels. Make sure to include the skip connections from the encoder. This can be done using torch's concatenation.\n",
    "\n",
    "- **Output Layers**: The goal is to transform the deep feature maps into our desired output. Depending on the task, this could be a segmentation mask, regression map, etc.\n",
    "\n",
    "Remember, the architecture of U-Net is symmetric. It might be helpful to sketch the network or list down the sizes of feature maps as you code.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boundary Conditions can be applied using a boundary mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetBC(UNet):\n",
    "    def __init__(self, order, mask):\n",
    "        super(UNetBC, self).__init__(order)\n",
    "        self.mask = mask\n",
    "\n",
    "    def forward(self, x_zeta, x_vel):\n",
    "        x_vel = x_vel * self.mask\n",
    "        dt_zeta, dt_vel = super(UNetBC, self).forward(x_zeta, x_vel)\n",
    "        dt_vel = dt_vel * self.mask\n",
    "        return dt_zeta, dt_vel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the U-Net Model\n",
    "\n",
    "After defining our U-Net architecture, it's time to set up a training loop. This loop will iteratively update our model's weights using our dataset. Let's break down the steps needed:\n",
    "\n",
    "1. **Setting Up**: Import necessary libraries, define hyperparameters, initialize computational device, and set random seeds.\n",
    "2. **Data Loading**: Load the training and validation datasets and create data loaders.\n",
    "3. **Model & Training Essentials Initialization**: Create mask, model, optimizer, and loss function.\n",
    "4. **Training Loop**: For each epoch, forward propagate the input through the model, compute the loss, backpropagate the errors, and update the model weights.\n",
    "5. **Validation Loop**: After training for each epoch, we will evaluate the model's performance on the validation dataset.\n",
    "6. **Logging & Visualization**: Log metrics such as losses to TensorBoard.\n",
    "7. **Model Saving**: After all epochs are completed, save the model's state dict.\n",
    "\n",
    "Let's get started with the skeleton and explanations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Setting Up\n",
    "\n",
    "First, we need to define some hyperparameters, which are constants that determine how the model will be trained. We also set a computational device (either a GPU or CPU) to ensure our tensors and model are loaded onto the right hardware.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 400\n",
    "LR = 0.001\n",
    "ORDER = 1  # Autoregressive model order\n",
    "NUMTIME = 600  # time steps per simulation\n",
    "EXP_NAME = 'plain_time_integrator'\n",
    "\n",
    "# Initialize TensorBoard writer for logging\n",
    "log_dir = f'runs/exp_{EXP_NAME}'\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    # This function ensures reproducibility\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data Loading\n",
    "\n",
    "Next, load the training and validation datasets. We also create data loaders that will allow us to fetch batches of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SWDataset(file_path=\"simulation_data.h5\", order=ORDER, numtime=NUMTIME, mode=\"train\")\n",
    "valid_dataset = SWDataset(file_path=\"simulation_data.h5\", order=ORDER, numtime=NUMTIME, mode=\"valid\")\n",
    "\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "dataloader_valid = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Model & Training Essentials Initialization\n",
    "\n",
    "Before training, initialize the model, the optimizer responsible for weight updates, and the loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader_train))\n",
    "input_vel_batch = batch[0][1]\n",
    "mask = torch.ones_like(input_vel_batch).to(device)\n",
    "mask[..., 0] = 0\n",
    "mask[..., -1] = 0\n",
    "\n",
    "model = UNetBC(order=ORDER, mask=mask).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 & 5: Training and Validation Loop\n",
    "\n",
    "The training loop involves:\n",
    "1. Setting the model to training mode.\n",
    "2. Iterating through batches of data from the dataloader.\n",
    "3. Making predictions using the model.\n",
    "4. Calculating the loss.\n",
    "5. Backpropagating to compute gradients.\n",
    "6. Updating model parameters using the optimizer.\n",
    "\n",
    "After each training epoch, you'll also run a validation loop to check the model's performance on unseen data. We will develop this training loop as a class which can take our UNet model as input, so when we make modifications to the architecture, we can still use this trainer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetTrainer:\n",
    "    def __init__(self, model, device, dataloader_train, dataloader_valid, optimizer, criterion, writer, epochs):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.dataloader_train = dataloader_train\n",
    "        self.dataloader_valid = dataloader_valid\n",
    "        self.writer = writer\n",
    "        self.epochs = epochs\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def train_epoch(self):\n",
    "        train_losses = []\n",
    "        self.model.train()\n",
    "\n",
    "        for (input_zeta, input_vel), (target_zeta, target_vel) in self.dataloader_train:\n",
    "            self.optimizer.zero_grad()\n",
    "            input_zeta, input_vel = input_zeta.to(self.device), input_vel.to(self.device)\n",
    "            target_zeta, target_vel = target_zeta.to(self.device), target_vel.to(self.device)\n",
    "            output_zeta_dt, output_vel_dt = self.model(input_zeta, input_vel)\n",
    "            output_zeta = input_zeta + output_zeta_dt\n",
    "            output_vel = input_vel + output_vel_dt\n",
    "            loss_zeta = self.criterion(output_zeta, target_zeta)\n",
    "            loss_vel = self.criterion(output_vel, target_vel)\n",
    "            total_loss = (loss_zeta + loss_vel) / 2.0\n",
    "            total_loss.backward()\n",
    "            self.optimizer.step()\n",
    "            train_losses.append(total_loss.item())\n",
    "\n",
    "        return np.mean(train_losses)\n",
    "\n",
    "    def validate_epoch(self):\n",
    "        valid_losses = []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for (input_zeta, input_vel), (targets_zeta, targets_vel) in self.dataloader_valid:\n",
    "                input_zeta, input_vel = input_zeta.to(self.device), input_vel.to(self.device)\n",
    "                targets_zeta, targets_vel = targets_zeta.to(self.device), targets_vel.to(self.device)\n",
    "                output_zeta_dt, output_vel_dt = self.model(input_zeta, input_vel)\n",
    "                output_zeta = input_zeta + output_zeta_dt\n",
    "                output_vel = input_vel + output_vel_dt\n",
    "                loss_zeta = self.criterion(output_zeta, targets_zeta)\n",
    "                loss_vel = self.criterion(output_vel, targets_vel)\n",
    "                combined_loss = (loss_zeta + loss_vel) / 2.0\n",
    "                valid_losses.append(combined_loss.item())\n",
    "\n",
    "        return np.mean(valid_losses)\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.epochs):\n",
    "            train_loss = self.train_epoch()\n",
    "            self.writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "\n",
    "            valid_loss = self.validate_epoch()\n",
    "            self.writer.add_scalar(\"Loss/valid\", valid_loss, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{self.epochs} Train Loss: {train_loss:.8f} Valid Loss: {valid_loss:.8f}\")\n",
    "\n",
    "trainer = UNetTrainer(model, device, dataloader_train, dataloader_valid, optimizer, criterion, writer, epochs=EPOCHS)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Logging & Visualization\n",
    "\n",
    "We've already added logging functionality in the training loop using TensorBoard's `SummaryWriter`. This will help visualize training and validation loss curves, among other metrics you might want to track.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir $log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Model Saving\n",
    "\n",
    "Finally, save the model's state dict, which contains the model's learned parameters. Later, you can load this state dict to make predictions with the trained model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), EXP_NAME + '.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Learning the flux values instead of tendencies\n",
    "Hyperbolic conservation laws can be written in the form:\n",
    "\n",
    "$\\dfrac{\\partial \\mathbf{U}}{\\partial t} + \\dfrac{\\partial \\mathbf{F}(\\mathbf{U})}{\\partial \\mathbf{x}}=\\mathbf{0}$\n",
    "\n",
    "Instead of outputting the tendencies $\\mathbf{U}_t$ for elevation $\\zeta$ and velocity $v$, we can also output the fluxes $\\mathbf{F}$ calculated on discretized domain corresponding to these variables.\n",
    "This will guarantee that our neural network will satisfy the conservation laws precisely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetFlux(UNet):\n",
    "    def __init__(self, order):\n",
    "        super(UNetFlux, self).__init__(order)\n",
    "        self.output_dec_zeta = nn.Conv1d(16, 1, kernel_size=4, padding=1)\n",
    "        self.output_dec_vel = nn.Conv1d(16, 1, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x_zeta, x_vel):\n",
    "        F_zeta, F_vel = super(UNetFlux, self).forward(x_zeta, x_vel)\n",
    "        zeta_flux = torch.diff(F_zeta, dim=-1)\n",
    "        vel_flux = torch.diff(F_vel, dim=-1)\n",
    "        vel_flux = torch.nn.functional.pad(vel_flux, (1, 1), \"constant\", 0)\n",
    "        zeta_flux = torch.nn.functional.pad(zeta_flux, (1, 1), \"constant\", 0)\n",
    "        return zeta_flux, vel_flux\n",
    "\n",
    "model = UNetFlux(order=1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "trainer = UNetTrainer(model, device, dataloader_train, dataloader_valid, optimizer, criterion, writer, epochs=EPOCHS)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Learning the $\\zeta$ values only using the UNet\n",
    "We can also output updates on $\\zeta$ values and use a hybrid approach to update the field variables. This approach uses the Imex integration scheme for the variables. The derivation of the discretized SWE in this case can be obtained with the following derivation,\n",
    "\n",
    "We discretize the momentum equation as follows:\n",
    "\n",
    "$u^{n+1} = u^n - \\Delta t C_D\\frac{1}{h}u^n|u^n|- \\Delta t g (1-w_{\\textbf{imp}}) \\frac{\\partial \\zeta^{n}}{\\partial x}-\\Delta t g w_{\\textbf{imp}} \\frac{\\partial \\zeta^{n+1}}{\\partial x}$\n",
    "\n",
    "where $w_{\\textbf{imp}}$ is a fixed parameter controlling weighting between implicit and explicit time stepping. The mass equation is discretized as:\n",
    "\n",
    "$\\zeta^{n+1} = \\zeta^n - \\Delta t (1-w_{\\textbf{imp}}) \\frac{\\partial h^n u^n}{\\partial x}-\\Delta t w_{\\textbf{imp}} \\frac{\\partial h^n u^{n+1}}{\\partial x}.\n",
    "$\n",
    "\n",
    "Recall that $h=d+\\zeta$ and $d$ is the undisturbed water depth. Inserting the momentum equation into the mass conservation equation, we obtain:\n",
    "\n",
    "$\\zeta^{n+1} = \\zeta^n - \\Delta t (1-w_{\\textbf{imp}}) \\frac{\\partial h^n u^n}{\\partial x}-\\Delta t w_{\\textbf{imp}} \\frac{\\partial h^nu^*}{\\partial x} + \\Delta t^2 w_{\\textbf{imp}}^2g\\frac{\\partial^2 h^n\\zeta^{n+1}}{\\partial x^2}$\n",
    "\n",
    "where $u^*$ is an explicit prediction for $u$:\n",
    "\n",
    "$u^* = u^n - \\Delta t c_D\\frac{1}{h}u^n|u^n|- \\Delta t g (1 - w_{\\textbf{imp}}) \\frac{\\partial \\zeta^{n}}{\\partial x}$\n",
    "\n",
    "The second order spatial derivatives are discretized using the second order finite central difference stencil. Then using $u^*$, we obtain the following expression for momentum equation:\n",
    "\n",
    "$\\zeta^{n+1}_i = \\frac{1}{1+c_E+c_W}\\bigg[\\zeta^n+\\text{div}+c_E\\zeta^{n+1}_{i+1}+c_W\\zeta^{n+1}_{i-1}\\bigg]$\n",
    "\n",
    "where $\\text{div} = - \\Delta t (1-w_{\\textbf{imp}})\\frac{\\partial h^n u^n}{\\partial x} -\\Delta t w_{\\textbf{imp}}\\frac{\\partial h^nu^*}{\\partial x}$, while $c_E$ and $c_W$ are defined as\n",
    "\n",
    "$c_E=\\frac{0.5\\Delta t^2w_{\\textbf{imp}}^2g (h_i^n+h_{i+1}^n)}{\\Delta x^2}$ if $h(i+1)>0$ and $0$ otherwise\n",
    "\n",
    "$c_W =\\frac{0.5\\Delta t^2w_{\\textbf{imp}}^2g (h_i^n+h_{i-1}^n)}{\\Delta x^2}$ if $h(i-1)>0$ and $0$ otherwise\n",
    "\n",
    "Then $\\zeta$ update equation describes a linear system of equations in $\\zeta^{n+1}$ that can be written in matrix-vector form\n",
    "\n",
    "$A \\zeta^{n+1} = b$\n",
    "\n",
    "where $A$ is a $N \\times N$ tridiagonal matrix ($N=L/\\Delta x$) with $A_{k,k}=1$, $A_{k, k - 1} = -\\frac{c_W}{1 + c_E + c_W}$, $A_{k, k + 1} = - \\frac{c_E}{1 + c_E + c_W}$ and all other elements zero. $b\\in\\mathbb R^N$ with $b = \\frac{\\zeta^n +div}{1 + c_E + c_W}$. Having obtained $\\zeta^{n+1}$, the new velocity $u^{n+1}$ is calculated as\n",
    "\n",
    "$u^{n+1} = u^* - \\Delta t g w_{\\textbf{imp}} \\frac{\\partial \\zeta^{n+1}}{\\partial x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###  Our tasks are as follows:\n",
    "\n",
    "1- First, modify our UNet architecture to output only one channel.\n",
    "\n",
    "2- Create the loss for updating the $\\zeta$ values using the equation system $A \\zeta^{n+1} = b$.\n",
    "\n",
    "3- Update the velocity values using the formula $v^{n+1} = v^* - \\Delta t g w_{\\textbf{imp}} \\frac{\\partial \\zeta^{n+1}}{\\partial x}$. Hence we need a function accomplishing this.\n",
    "\n",
    "4-  Update the batch size and mask tensor. Call the dataset class for the initial conditions and disable normalization.\n",
    "\n",
    "5- Modify the training loop of our model.\n",
    "\n",
    "6- Run the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Architecture\n",
    "class ZetaUNet(UNetBC):\n",
    "    def __init__(self, order, mask):\n",
    "        super(ZetaUNet, self).__init__(order, mask)\n",
    "        self.order = order\n",
    "        self.mask = mask\n",
    "\n",
    "    def forward(self, x_zeta, x_vel):\n",
    "        zeta_dt, _ = super(ZetaUNet, self).forward(x_zeta, x_vel)\n",
    "        return zeta_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New physics informed loss function\n",
    "# Parameters for the given dataset of SWE.\n",
    "CD = 1.0e-3\n",
    "G = 9.81\n",
    "DT = 300.0\n",
    "W_IMP = 0.5\n",
    "H0 = 100.0\n",
    "DX = 10.0e3\n",
    "N = 256\n",
    "\n",
    "class HybridLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HybridLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, zeta_dt, zeta_n, vel_n):\n",
    "        h_n = H0 + zeta_n\n",
    "        h_m = (h_n[..., 1:] + h_n[..., :-1]) / 2.0\n",
    "\n",
    "        zeta_dx = torch.diff(zeta_n, axis=-1) / DX\n",
    "        zeta_dx = torch.nn.functional.pad(zeta_dx, (1, 1), \"constant\", 0)\n",
    "        h_m = torch.nn.functional.pad(h_m, (1, 1), \"constant\", 1)\n",
    "        vel_star = (\n",
    "            vel_n\n",
    "            - DT * CD * torch.div(torch.mul(torch.abs(vel_n), vel_n), h_m)\n",
    "            - DT * G * (1 - W_IMP) * zeta_dx\n",
    "            - DT * G * W_IMP * zeta_dx\n",
    "        )\n",
    "        U = torch.mul(vel_n, h_m)\n",
    "        U_star = torch.mul(vel_star, h_m)\n",
    "        U_dx = (torch.diff(U, axis=-1)) / DX\n",
    "        U_star_dx = (torch.diff(U_star, axis=-1)) / DX\n",
    "        div = -DT * (1 - W_IMP) * U_dx - DT * W_IMP * U_star_dx\n",
    "\n",
    "        h_e = h_n + torch.roll(h_n, shifts=-1, dims=-1)\n",
    "        h_w = h_n + torch.roll(h_n, shifts=1, dims=-1)\n",
    "        h_e[..., -1] = 2 * h_n[..., -1]\n",
    "        h_w[..., 0] = 2 * h_n[..., 0]\n",
    "\n",
    "        h_e_dx2 = (h_e[..., :-2] - 2 * h_e[..., 1:-1] + h_e[..., 2:]) / (DX**2)\n",
    "        h_w_dx2 = (h_w[..., :-2] - 2 * h_w[..., 1:-1] + h_w[..., 2:]) / (DX**2)\n",
    "\n",
    "        c_e = DT**2 * W_IMP**2 * G * h_e_dx2\n",
    "        c_w = DT**2 * W_IMP**2 * G * h_w_dx2\n",
    "        diag_c = torch.ones(N)\n",
    "        diag_cm1 = torch.div(-c_w, 1 + c_e + c_w)\n",
    "        diag_cp1 = torch.div(-c_e, 1 + c_e + c_w)\n",
    "        diag_cm1 = torch.nn.functional.pad(diag_cm1, (1, 0), \"constant\", 0)\n",
    "        diag_cp1 = torch.nn.functional.pad(diag_cp1, (0, 1), \"constant\", 0)\n",
    "        b = torch.div(zeta_n[..., 1:-1] + div[..., 1:-1], 1 + c_e + c_w)\n",
    "        b = torch.nn.functional.pad(b, (1, 1), \"constant\", 0)\n",
    "        zeta_new = zeta_n + zeta_dt\n",
    "        A = torch.zeros(BATCH_SIZE, 1, N, N)\n",
    "        A[..., torch.arange(N), torch.arange(N)] = diag_c\n",
    "        A[..., torch.arange(N - 1), torch.arange(1, N)] = diag_cm1\n",
    "        A[..., torch.arange(1, N), torch.arange(N - 1)] = diag_cp1\n",
    "        loss = self.mse_loss(torch.matmul(A, zeta_new.unsqueeze(-1)), b.unsqueeze(-1))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Velocity Integration function\n",
    "def integrate_vel(vel_n, zeta_new, zeta_old):\n",
    "    h_n = H0 + zeta_old\n",
    "    h_m = (h_n[..., 1:] + h_n[..., :-1]) / 2.0\n",
    "\n",
    "    zeta_old_dx = torch.diff(zeta_old, axis=-1) / DX\n",
    "    zeta_new_dx = torch.diff(zeta_new, axis=-1) / DX\n",
    "    zeta_old_dx = torch.nn.functional.pad(zeta_old_dx, (1, 1), \"constant\", 0)\n",
    "    zeta_new_dx = torch.nn.functional.pad(zeta_new_dx, (1, 1), \"constant\", 0)\n",
    "    h_m = torch.nn.functional.pad(h_m, (1, 1), \"constant\", 1)\n",
    "\n",
    "    vel_star = (\n",
    "        vel_n\n",
    "        - DT * CD * torch.div(torch.mul(torch.abs(vel_n), vel_n), h_m)\n",
    "        - DT * G * (1 - W_IMP) * zeta_old_dx\n",
    "        - DT * G * W_IMP * zeta_new_dx\n",
    "    )\n",
    "    vel_new = vel_star - DT * G * W_IMP * zeta_new_dx\n",
    "    return vel_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "train_dataset = SWDataset(file_path=\"simulation_data.h5\", order=ORDER, numtime=NUMTIME, mode=\"train\", normalize=False)\n",
    "valid_dataset = SWDataset(file_path=\"simulation_data.h5\", order=ORDER, numtime=NUMTIME, mode=\"valid\", normalize=False)\n",
    "\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "dataloader_valid = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop for the hybrid model\n",
    "class PITrainerZeta:\n",
    "    def __init__(self, model, device, train_dataset, optimizer, criterion, writer, epochs):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.train_dataset = train_dataset\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.writer = writer\n",
    "        self.EPOCHS = EPOCHS\n",
    "        self.NUMTIME = NUMTIME\n",
    "    def train_epoch(self):\n",
    "        train_losses = []\n",
    "        self.model.train()\n",
    "\n",
    "        init_zeta, init_vel = self.train_dataset.get_initial_conditions()\n",
    "        self.optimizer.zero_grad()\n",
    "        accumulated_loss = 0\n",
    "        input_zeta, input_vel = init_zeta.to(self.device), init_vel.to(self.device)\n",
    "\n",
    "        for _ in range(self.NUMTIME):\n",
    "            output_zeta_dt = self.model(input_zeta, input_vel)\n",
    "            next_zeta = input_zeta + output_zeta_dt\n",
    "            next_vel = integrate_vel(input_vel, next_zeta, input_zeta)\n",
    "\n",
    "            unsupervised_loss = self.criterion(output_zeta_dt, input_zeta, input_vel)\n",
    "            accumulated_loss += unsupervised_loss\n",
    "\n",
    "            input_zeta, input_vel = next_zeta, next_vel\n",
    "\n",
    "        accumulated_loss.backward()\n",
    "        self.optimizer.step()\n",
    "        train_losses.append(accumulated_loss.item())\n",
    "\n",
    "        return np.mean(train_losses)\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.EPOCHS):\n",
    "            train_loss = self.train_epoch()\n",
    "            self.writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}/{self.EPOCHS} Train Loss: {train_loss:.8f}\"\n",
    "            )\n",
    "\n",
    "        torch.save(self.model.state_dict(), \"unet_model.pth\")\n",
    "\n",
    "batch = next(iter(dataloader_train))\n",
    "input_vel_batch = batch[0][1]\n",
    "mask = torch.ones_like(input_vel_batch).to(device)\n",
    "mask[..., 0] = 0\n",
    "mask[..., -1] = 0\n",
    "model = ZetaUNet(order=ORDER, mask=mask).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = HybridLoss()\n",
    "trainer = PITrainerZeta(model, device, train_dataset, optimizer, criterion, writer, epochs=EPOCHS)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Physical Constraints Using the semi-implicit discretization\n",
    "\n",
    "The physical constraints can also be applied using the discretized form of the SWE. Network can output both velocity and elevations and the outputs can be forced to satisfy the following discretized equation\n",
    "\n",
    "$u^{n+1} = u^n - \\Delta t C_D\\frac{1}{h}u^n|u^n|- \\Delta t g (1-w_{\\textbf{imp}}) \\frac{\\partial \\zeta^{n}}{\\partial x}-\\Delta t g w_{\\textbf{imp}} \\frac{\\partial \\zeta^{n+1}}{\\partial x}$\n",
    "\n",
    "$\\zeta^{n+1} = \\zeta^n - \\Delta t (1-w_{\\textbf{imp}}) \\frac{\\partial h^n u^n}{\\partial x}-\\Delta t w_{\\textbf{imp}} \\frac{\\partial h^n u^{n+1}}{\\partial x}.\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###  Our tasks are as follows:\n",
    "\n",
    "1- Create the loss for updating the $\\zeta$ and $v$ values using the semi implicit discretization of SWE.\n",
    "\n",
    "2- Call the UNet model which outputs both field variables.\n",
    "\n",
    "3- Modify the training loop of our model.\n",
    "\n",
    "4- Run the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physics informed loss function for Semi implicit discretized SWE\n",
    "class SemiImpLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SemiImpLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, zeta_dt, vel_dt, zeta_n, vel_n):\n",
    "        h_n = H0 + zeta_n\n",
    "        h_n_tilde = (h_n[..., :-1] + h_n[..., 1:]) / 2.0\n",
    "\n",
    "        zeta_nx = torch.diff(zeta_n, axis=-1) / DX\n",
    "        zeta_n1x = torch.diff(zeta_n + zeta_dt, axis=-1) / DX\n",
    "        zeta_nx = torch.nn.functional.pad(zeta_nx, (1, 1), \"constant\", 0)\n",
    "        zeta_n1x = torch.nn.functional.pad(zeta_n1x, (1, 1), \"constant\", 0)\n",
    "\n",
    "        h_n_tilde = torch.nn.functional.pad(h_n_tilde, (1, 1), \"constant\", 1)\n",
    "\n",
    "        U_nx = torch.diff(torch.mul(h_n_tilde, vel_n))\n",
    "        U_n1x = torch.diff(torch.mul(h_n_tilde, vel_n + vel_dt))\n",
    "\n",
    "        mass_loss = vel_dt + DT * (\n",
    "            CD * torch.div(torch.mul(vel_n, torch.abs(vel_n)), h_n_tilde)\n",
    "            + G * (1 - W_IMP) * zeta_nx\n",
    "            + G * W_IMP * zeta_n1x\n",
    "        )\n",
    "        mom_loss = zeta_dt + DT * (1 - W_IMP) * U_nx + DT * W_IMP * U_n1x\n",
    "\n",
    "        loss1 = torch.mean(mass_loss**2)\n",
    "        loss2 = torch.mean(mom_loss**2)\n",
    "\n",
    "        return loss1 + loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop for the hybrid model\n",
    "class PITrainerZetaV:\n",
    "    def __init__(self, model, device, train_dataset, optimizer, criterion, writer, epochs):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.train_dataset = train_dataset\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.writer = writer\n",
    "        self.EPOCHS = EPOCHS\n",
    "\n",
    "    def train_epoch(self):\n",
    "        train_losses = []\n",
    "        self.model.train()\n",
    "\n",
    "        init_zeta, init_vel = self.train_dataset.get_initial_conditions()\n",
    "        self.optimizer.zero_grad()\n",
    "        accumulated_loss = 0\n",
    "        input_zeta, input_vel = init_zeta.to(self.device), init_vel.to(self.device)\n",
    "\n",
    "        for _ in range(self.NUMTIME):\n",
    "            output_zeta_dt, output_vel_dt = self.model(input_zeta, input_vel, mask)\n",
    "            next_zeta = input_zeta + output_zeta_dt\n",
    "            next_vel = input_vel + output_vel_dt\n",
    "\n",
    "            unsupervised_loss = self.criterion(output_zeta_dt, output_vel_dt, input_zeta, input_vel)\n",
    "            accumulated_loss += unsupervised_loss\n",
    "\n",
    "            input_zeta, input_vel = next_zeta, next_vel\n",
    "\n",
    "        accumulated_loss.backward()\n",
    "        self.optimizer.step()\n",
    "        train_losses.append(accumulated_loss.item())\n",
    "\n",
    "        return np.mean(train_losses)\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.EPOCHS):\n",
    "            train_loss = self.train_epoch()\n",
    "            self.writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}/{self.EPOCHS} Train Loss: {train_loss:.8f}\"\n",
    "            )\n",
    "\n",
    "        torch.save(self.model.state_dict(), \"unet_model.pth\")\n",
    "\n",
    "model = UnetMask(order=ORDER).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = SemiImpLoss()\n",
    "trainer = PITrainerZetaV(model, device, dataloader_train, optimizer, criterion, writer, epochs=EPOCHS)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Equivariant Convolutions?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
